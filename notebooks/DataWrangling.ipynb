{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17fb1e3",
   "metadata": {},
   "source": [
    "# Data Collection:\n",
    "\n",
    "Data Loading: Use the code to fetch data from The MET API and save it to a CSV file (metdata.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9bfc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 487594 valid objects in this dataset\n",
      "The column headers are the following: dict_keys(['objectID', 'isHighlight', 'accessionNumber', 'accessionYear', 'isPublicDomain', 'primaryImage', 'primaryImageSmall', 'additionalImages', 'constituents', 'department', 'objectName', 'title', 'culture', 'period', 'dynasty', 'reign', 'portfolio', 'artistRole', 'artistPrefix', 'artistDisplayName', 'artistDisplayBio', 'artistSuffix', 'artistAlphaSort', 'artistNationality', 'artistBeginDate', 'artistEndDate', 'artistGender', 'artistWikidata_URL', 'artistULAN_URL', 'objectDate', 'objectBeginDate', 'objectEndDate', 'medium', 'dimensions', 'measurements', 'creditLine', 'geographyType', 'city', 'state', 'county', 'country', 'region', 'subregion', 'locale', 'locus', 'excavation', 'river', 'classification', 'rightsAndReproduction', 'linkResource', 'metadataDate', 'repository', 'objectURL', 'tags', 'objectWikidata_URL', 'isTimelineWork', 'GalleryNumber'])\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Use The MET API to get the object IDs\n",
    "r = requests.get(\"https://collectionapi.metmuseum.org/public/collection/v1/objects\")\n",
    "r_json = r.json()\n",
    "total = r_json['total']\n",
    "print(\"There are {} valid objects in this dataset\".format(total))\n",
    "objectIDs = r_json['objectIDs']\n",
    "\n",
    "# get the column headers from the first object ID\n",
    "prefix = \"https://collectionapi.metmuseum.org/public/collection/v1/objects/\"\n",
    "url = prefix + str(objectIDs[0])\n",
    "r = requests.get(url)\n",
    "col_headers = r.json().keys()\n",
    "\n",
    "# create the csv file and write the first row\n",
    "filename = 'metdata.csv'  # Adjust the file path as needed\n",
    "\n",
    "# remove if it already exists\n",
    "try:\n",
    "    os.remove(filename)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "print(\"The column headers are the following: {}\".format(col_headers))\n",
    "\n",
    "# Write data to CSV\n",
    "with open(filename, 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(col_headers)\n",
    "    \n",
    "    for index, ID in enumerate(objectIDs):\n",
    "        url = prefix + str(ID)\n",
    "        r = requests.get(url)\n",
    "        values = r.json().values()\n",
    "        csv_writer.writerow(values)\n",
    "        # print out each of the rows by their index\n",
    "        print(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1fcfc",
   "metadata": {},
   "source": [
    "# Data Organization:\n",
    "\n",
    "File Structure & GitHub:\n",
    "Create a directory structure.\n",
    "Add the metdata.csv file to the project's GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Create file structure\n",
    "data_folder = ''  # Adjust the folder structure as needed\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "# Add data to GitHub\n",
    "# Assuming you have already initialized a Git repository and added a remote to GitHub\n",
    "# You can add and commit the data file to the repository\n",
    "os.system('git add data/metdata.csv')\n",
    "os.system('git commit -m \"Added MET dataset\"')\n",
    "os.system('git push origin master')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9908c94",
   "metadata": {},
   "source": [
    "# Data Definition:\n",
    "Understanding Data Features:\n",
    "Analyze column names, data types, description, counts, unique values, and ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb02790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('metdata.csv')\n",
    "\n",
    "# Analyze column names, data types, description, counts, unique values, and ranges\n",
    "column_names = df.columns\n",
    "data_types = df.dtypes\n",
    "description = df.describe()\n",
    "unique_values_counts = df.nunique()\n",
    "value_ranges = df.max() - df.min()\n",
    "\n",
    "# Print or visualize the analysis\n",
    "print(\"Column Names:\", column_names)\n",
    "print(\"Data Types:\", data_types)\n",
    "print(\"Description:\", description)\n",
    "print(\"Unique Values Counts:\", unique_values_counts)\n",
    "print(\"Value Ranges:\", value_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21363fda",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    "Handle missing values and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Handle duplicates\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df_cleaned.to_csv('/metdata_cleaned.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
